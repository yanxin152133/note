# 1. 分布式文件存储系统HDFS
## 1.1. 介绍
>HDFS（Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错、高吞吐量等特性，可以部署在低成本的硬件上。HDFS能提供高吞吐量的数据访问，适合大规模数据集上的应用。HDFS放宽了一部分POSIX的约束，来实现流式读取文件系统的数据。HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的，它是Apache Hadoop核心项目的一部分。
     
## 1.2. HDFS设计原理
![HDFS设计原理](https://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif)
      
### 1.2.1. HDFS架构
HDFS遵循`主从架构`，一个HDFS集群是由单个`NameNode(NN)`和多个`DataNode(DN)`组成，`NameNode`是一个管理文件系统命名空间和调节客户端访问文件的主服务器，`DataNode`是管理对应节点的存储，通常是一个服务器部署一个DataNode。内部的，一个文件被分割为一个或多个数据块，这些数据块被存储在不同的DataNode。
     
- NameNode：负责执行有关`文件系统命名空间`的操作，例如打开、关闭、重命名文件和目录等。它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。
- DataNode：负责提供来自文件系统客户端的读写请求，执行块的创建、删除等操作。
      
### 1.2.2. 文件系统命名空间
HDFS的`文件系统命名空间`的层次结构与大多数文件系统类似（如Linux），支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。`NameNode`负责维护文件系统名称空间，记录对名称空间或其属性的任何更改。应用程序可以指定文件的`副本数`，该数值被称为文件的`复制因子`，这些信息会有`NameNode`负责保存。
        
        
### 1.2.3. 数据复制
由于Hadoop被设计运行在廉价的机器上，HDFS用于在大型集群中的服务器之间可靠地存储非常大的文件。它把每一个文件存储为序列的块，这些序列块会被复制用于容错，每个文件的块大小和复制因子是可以配置的。每个块由多个副本来保证容错，块的大小和复制因子可以自行配置（`默认情况下，块大小是 128M，默认复制因子是 3`）。同一文件中除了最后一个块之外，其他块的大小都是相同的。
     
![数据复制](https://hadoop.apache.org/docs/r1.2.1/images/hdfsdatanodes.gif)
     
### 1.2.4. 数据复制的实现原理
大型的 HDFS 实例在通常分布在多个机架的多台服务器上，不同机架上的两台服务器之间通过交换机进行通讯。在大多数情况下，同一机架中的服务器间的网络带宽大于不同机架中的服务器之间的带宽。因此 HDFS 采用机架感知副本放置策略，对于常见情况，当复制因子为 3 时，HDFS 的放置策略是：
         
在写入程序位于 datanode 上时，就优先将写入文件的一个副本放置在该 datanode 上，否则放在随机 datanode 上。之后在另一个远程机架上的任意一个节点上放置另一个副本，并在该机架上的另一个节点上放置最后一个副本。此策略可以减少机架间的写入流量，从而提高写入性能。
      
![数据复制原理](https://camo.githubusercontent.com/13a6efeb0f206fb5bceae8b1fbfe5756f70ee0a4/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f686466732de69cbae69eb62e706e67)
       
如果复制因子大于 3，则随机确定第 4 个和之后副本的放置位置，同时保持每个机架的副本数量低于上限，上限值通常为`（复制系数 - 1）/机架数量 + 2`，需要注意的是不允许同一个dataNode上具有同一个块的多个副本。
      
### 1.2.5. 副本的选择
为了最大限度地减少带宽消耗和读取延迟，HDFS 在执行读取请求时，优先读取距离读取器最近的副本。如果在与读取器节点相同的机架上存在副本，则优先选择该副本。如果 HDFS 群集跨越多个数据中心，则优先选择本地数据中心上的副本。
       
### 1.2.6. 安全模式
在HDFS启动的时候，NameNode会进入一个叫安全模式Safemode的特别状态，在此模式下，数据块还不会被复制。NameNode接收来自DataNodes的心跳和Blockreport信息，一份Blockreport包含该DataNode所有块的列表。每一个块有一个特定的最小复制数，当数据块的最小复制数被NameNode检查后，就认为是复制成功。当达到配置的块复制安全比例时（加上额外的30秒），NameNode就退出安全模式状态。然后，它会检测数据块的列表，把少于指定数量副本的数据块复制到其它的DataNodes。
      
### 1.2.7. HDFS故障类型
HDFS故障类型：节点故障、通讯故障和数据损坏。
      
### 1.2.8. 架构的稳定性
#### 1.2.8.1. 心跳机制和重新复制
每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值，NameNode 会跟踪这些块，并在必要的时候进行重新复制。
       
#### 1.2.8.2. 数据的完整性
由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下：
     
当客户端创建 HDFS 文件时，它会计算文件的每个块的`校验和`，并将`校验和`存储在同一 HDFS 命名空间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的`校验和`匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。
        
#### 1.2.8.3. 元数据的磁盘故障
`FsImage`和`EditLog`是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可用。为了避免这个问题，可以配置 NameNode 使其支持`FsImage`和`EditLog`多副本同步，这样`FsImage`或`EditLog`的任何改变都会引起每个副本`FsImage`和`EditLog`的同步更新。
     
#### 1.2.8.4. 支持快照
快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。
#### 1.2.8.5. 通讯协议
所有HDFS通信协议都位于TCP / IP协议之上。客户端建立与NameNode计算机上可配置TCP端口的连接。它将ClientProtocol与NameNode进行通信。DataNode使用DataNode协议与NameNode对话。远程过程调用（RPC）抽象包装了客户端协议和DataNode协议。按照设计，NameNode永远不会启动任何RPC。相反，它仅响应由DataNode或客户端发出的RPC请求。
      
#### 1.2.8.6. 集群再平衡
HDFS体系结构与数据重新平衡方案兼容。如果DataNode的可用空间低于某个阈值，则方案可能会自动将数据从一个DataNode移到另一个DataNode。如果对特定文件的需求突然增加，则方案可能会动态创建其他副本并重新平衡群集中的其他数据。这些类型的数据重新平衡方案尚未实现。
      
## 1.3. HDFS的特点
### 1.3.1. 高容错
由于 HDFS 采用数据的多副本方案，所以部分硬件的损坏不会导致全部数据的丢失。
### 1.3.2. 高吞吐量
HDFS 设计的重点是支持高吞吐量的数据访问，而不是低延迟的数据访问。
### 1.3.3. 大文件支持
HDFS 适合于大文件的存储，文档的大小应该是是 GB 到 TB 级别的。
### 1.3.4. 简单一致性模型
HDFS 更适合于一次写入多次读取 (write-once-read-many) 的访问模型。支持将内容追加到文件末尾，但不支持数据的随机访问，不能从文件任意位置新增数据。
### 1.3.5. 跨平台移植性
HDFS 具有良好的跨平台移植性，这使得其他大数据计算框架都将其作为数据持久化存储的首选方案。
      
# 2. HDFS 原理图解
[HDFS 原理图解](https://blog.csdn.net/hudiefenmu/article/details/37655491)